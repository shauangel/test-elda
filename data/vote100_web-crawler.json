{"items":[{"tags":["python","web-crawler","python-requests"],"owner":{"user_type":"does_not_exist","display_name":"user1289853"},"is_answered":true,"view_count":418418,"accepted_answer_id":10606260,"answer_count":4,"score":307,"last_activity_date":1655730778,"creation_date":1337104124,"last_edit_date":1440587487,"question_id":10606133,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/10606133/sending-user-agent-using-requests-library-in-python","title":"Sending &quot;User-agent&quot; using Requests library in Python"},{"tags":["python","python-3.x","web-crawler"],"migrated_from":{"other_site":{"aliases":["https://programmer.stackexchange.com","https://programmers.stackexchange.com","https://swe.stackexchange.com"],"styling":{"tag_background_color":"#FFF","tag_foreground_color":"#5D5D5D","link_color":"#0077CC"},"related_sites":[{"relation":"meta","api_site_parameter":"softwareengineering.meta","site_url":"https://softwareengineering.meta.stackexchange.com","name":"Software Engineering Meta Stack Exchange"},{"relation":"chat","site_url":"https://chat.stackexchange.com?tab=site&host=softwareengineering.stackexchange.com","name":"Chat Stack Exchange"}],"markdown_extensions":["Prettify"],"launch_date":1292524346,"open_beta_date":1283972400,"closed_beta_date":1283367600,"site_state":"normal","high_resolution_icon_url":"https://cdn.sstatic.net/Sites/softwareengineering/Img/apple-touch-icon@2.png","twitter_account":"StackSoftEng","favicon_url":"https://cdn.sstatic.net/Sites/softwareengineering/Img/favicon.ico","icon_url":"https://cdn.sstatic.net/Sites/softwareengineering/Img/apple-touch-icon.png","audience":"professionals, academics, and students working within the systems development life cycle","site_url":"https://softwareengineering.stackexchange.com","api_site_parameter":"softwareengineering","logo_url":"https://cdn.sstatic.net/Sites/softwareengineering/Img/logo.png","name":"Software Engineering","site_type":"main_site"},"on_date":1435129407,"question_id":287424},"owner":{"account_id":2711267,"reputation":2109,"user_id":4949315,"user_type":"registered","accept_rate":75,"profile_image":"https://www.gravatar.com/avatar/3f047a5b040542f9109df507800500fe?s=256&d=identicon&r=PG","display_name":"Inspired_Blue","link":"https://stackoverflow.com/users/4949315/inspired-blue"},"is_answered":true,"view_count":264871,"accepted_answer_id":31019855,"answer_count":4,"score":160,"last_activity_date":1663474671,"creation_date":1434864289,"last_edit_date":1554809352,"question_id":31019854,"link":"https://stackoverflow.com/questions/31019854/typeerror-cant-use-a-string-pattern-on-a-bytes-like-object-in-re-findall","title":"TypeError: can&#39;t use a string pattern on a bytes-like object in re.findall()"},{"tags":["python","beautifulsoup","scrapy","web-crawler"],"owner":{"account_id":3464510,"reputation":2817,"user_id":2900495,"user_type":"registered","accept_rate":74,"profile_image":"https://i.stack.imgur.com/1XqSp.jpg?s=256&g=1","display_name":"Nishant Bhakta","link":"https://stackoverflow.com/users/2900495/nishant-bhakta"},"is_answered":true,"view_count":88008,"protected_date":1551701825,"accepted_answer_id":19734213,"answer_count":10,"score":155,"last_activity_date":1664731512,"creation_date":1383147803,"last_edit_date":1460477628,"question_id":19687421,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/19687421/difference-between-beautifulsoup-and-scrapy-crawler","title":"Difference between BeautifulSoup and Scrapy crawler?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":2108304,"reputation":2545,"user_id":1874105,"user_type":"registered","accept_rate":74,"profile_image":"https://i.stack.imgur.com/PHZzq.jpg?s=256&g=1","display_name":"L Lawliet","link":"https://stackoverflow.com/users/1874105/l-lawliet"},"is_answered":true,"view_count":73431,"accepted_answer_id":15618520,"answer_count":5,"score":125,"last_activity_date":1580219772,"creation_date":1364204113,"last_edit_date":1547321356,"question_id":15611605,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/15611605/how-to-pass-a-user-defined-argument-in-scrapy-spider","title":"How to pass a user defined argument in scrapy spider"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":918371,"reputation":2830,"user_id":950648,"user_type":"registered","accept_rate":54,"profile_image":"https://www.gravatar.com/avatar/9930622b76d8a140c06e1b395ae488b9?s=256&d=identicon&r=PG","display_name":"CodeMonkeyB","link":"https://stackoverflow.com/users/950648/codemonkeyb"},"is_answered":true,"view_count":31246,"accepted_answer_id":14165844,"answer_count":10,"score":97,"last_activity_date":1605950393,"creation_date":1322964505,"last_edit_date":1322970288,"question_id":8372703,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8372703/how-can-i-use-different-pipelines-for-different-spiders-in-a-single-scrapy-proje","title":"How can I use different pipelines for different spiders in a single Scrapy project"},{"tags":["python","web-scraping","web-crawler","scrapy"],"owner":{"account_id":2004686,"reputation":959,"user_id":1832978,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/c00c9a2474533cc449389f2fd8ce3e7e?s=256&d=identicon&r=PG","display_name":"user47954","link":"https://stackoverflow.com/users/1832978/user47954"},"is_answered":true,"view_count":81307,"answer_count":8,"score":85,"last_activity_date":1603453325,"creation_date":1353211789,"last_edit_date":1353229155,"question_id":13437402,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/13437402/how-to-run-scrapy-from-within-a-python-script","title":"How to run Scrapy from within a Python script"},{"tags":["python","web-crawler","pypi"],"owner":{"account_id":482881,"reputation":2603,"user_id":897578,"user_type":"registered","accept_rate":88,"profile_image":"https://www.gravatar.com/avatar/8580366366829c1dab132aad7a519f86?s=256&d=identicon&r=PG","display_name":"jeffalstott","link":"https://stackoverflow.com/users/897578/jeffalstott"},"is_answered":true,"view_count":10608,"accepted_answer_id":14726265,"answer_count":4,"score":73,"last_activity_date":1489400526,"creation_date":1331396594,"question_id":9648015,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/9648015/pypi-download-counts-seem-unrealistic","title":"PyPi download counts seem unrealistic"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":8459079,"reputation":693,"user_id":6345426,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/a6cf852a1d42d063d749cf33accbbbf2?s=256&d=identicon&r=PG&f=1","display_name":"deepak kumar","link":"https://stackoverflow.com/users/6345426/deepak-kumar"},"is_answered":true,"view_count":51436,"accepted_answer_id":37278895,"answer_count":3,"score":69,"last_activity_date":1598962704,"creation_date":1463484513,"question_id":37274835,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/37274835/getting-forbidden-by-robots-txt-scrapy","title":"getting Forbidden by robots.txt: scrapy"},{"tags":["python","web-crawler"],"owner":{"account_id":877090,"reputation":3056,"user_id":50522,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/3d4726df90252ca95270b398b49e8874?s=256&d=identicon&r=PG","display_name":"Matt","link":"https://stackoverflow.com/users/50522/matt"},"is_answered":true,"view_count":97421,"protected_date":1317805568,"accepted_answer_id":419259,"answer_count":8,"score":67,"locked_date":1344221388,"last_activity_date":1322569923,"creation_date":1231304001,"last_edit_date":1292900659,"question_id":419235,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/419235/anyone-know-of-a-good-python-based-web-crawler-that-i-could-use","title":"Anyone know of a good Python based web crawler that I could use?"},{"tags":["python","web-crawler","web-scraping","scrapy"],"owner":{"account_id":328759,"reputation":3854,"user_id":651894,"user_type":"registered","accept_rate":91,"profile_image":"https://www.gravatar.com/avatar/d323b88aab845494f2329b9f07979686?s=256&d=identicon&r=PG","display_name":"naeg","link":"https://stackoverflow.com/users/651894/naeg"},"is_answered":true,"view_count":73288,"accepted_answer_id":6682557,"answer_count":4,"score":65,"last_activity_date":1641114358,"creation_date":1310575509,"question_id":6682503,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/6682503/click-a-button-in-scrapy","title":"Click a Button in Scrapy"},{"tags":["python","twitter","web-crawler"],"owner":{"account_id":903434,"reputation":821,"user_id":938925,"user_type":"registered","accept_rate":25,"profile_image":"https://www.gravatar.com/avatar/4c22a6d9636d4e95b0d94b1bf626e982?s=256&d=identicon&r=PG","display_name":"Nama Keru","link":"https://stackoverflow.com/users/938925/nama-keru"},"is_answered":true,"view_count":196745,"protected_date":1526983384,"answer_count":5,"score":65,"last_activity_date":1642681579,"creation_date":1326261255,"last_edit_date":1397509862,"question_id":8814802,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8814802/python-errno-10054-an-existing-connection-was-forcibly-closed-by-the-remote-h","title":"python: [Errno 10054] An existing connection was forcibly closed by the remote host"},{"tags":["python","algorithm","recursion","web-crawler","depth"],"owner":{"account_id":437748,"reputation":1166,"user_id":825597,"user_type":"registered","accept_rate":75,"profile_image":"https://www.gravatar.com/avatar/0779368991670df704b4e3b2cb214f24?s=256&d=identicon&r=PG","display_name":"YSY","link":"https://stackoverflow.com/users/825597/ysy"},"is_answered":true,"view_count":236312,"accepted_answer_id":6809450,"answer_count":6,"score":60,"last_activity_date":1643813525,"creation_date":1311538499,"question_id":6809402,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/6809402/python-maximum-recursion-depth-exceeded-while-calling-a-python-object","title":"Python: maximum recursion depth exceeded while calling a Python object"},{"tags":["python","google-chrome","selenium","web-scraping","web-crawler"],"owner":{"account_id":2968576,"reputation":4806,"user_id":2521204,"user_type":"registered","accept_rate":12,"profile_image":"https://i.stack.imgur.com/NpzZe.png?s=256&g=1","display_name":"1man","link":"https://stackoverflow.com/users/2521204/1man"},"is_answered":true,"view_count":61876,"answer_count":3,"score":57,"last_activity_date":1543495419,"creation_date":1421852480,"last_edit_date":1495540042,"question_id":28070315,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/28070315/python-disable-images-in-selenium-google-chromedriver","title":"Python: Disable images in Selenium Google ChromeDriver"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":1686831,"reputation":743,"user_id":1549934,"user_type":"registered","accept_rate":33,"profile_image":"https://www.gravatar.com/avatar/901bc3742133260798b6c14333224bb3?s=256&d=identicon&r=PG","display_name":"nik-v","link":"https://stackoverflow.com/users/1549934/nik-v"},"is_answered":true,"view_count":18693,"accepted_answer_id":13605919,"answer_count":5,"score":42,"last_activity_date":1580219953,"creation_date":1348410306,"last_edit_date":1432075686,"question_id":12553117,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/12553117/how-to-filter-duplicate-requests-based-on-url-in-scrapy","title":"how to filter duplicate requests based on url in scrapy"},{"tags":["python","scrapy","web-crawler","screen-scraping","user-agent"],"owner":{"account_id":1703550,"reputation":18102,"user_id":1953475,"user_type":"registered","accept_rate":71,"profile_image":"https://i.stack.imgur.com/xbP7V.jpg?s=256&g=1","display_name":"B.Mr.W.","link":"https://stackoverflow.com/users/1953475/b-mr-w"},"is_answered":true,"view_count":52464,"accepted_answer_id":18922842,"answer_count":2,"score":40,"last_activity_date":1501515832,"creation_date":1379692356,"last_edit_date":1413524147,"question_id":18920930,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/18920930/scrapy-python-set-up-user-agent","title":"Scrapy Python Set up User Agent"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":1376197,"reputation":629,"user_id":1310147,"user_type":"registered","accept_rate":55,"profile_image":"https://www.gravatar.com/avatar/b2de928642e319f6468dcad6854ec2d4?s=256&d=identicon&r=PG","display_name":"Nits","link":"https://stackoverflow.com/users/1310147/nits"},"is_answered":true,"view_count":52242,"protected_date":1585594384,"answer_count":3,"score":35,"last_activity_date":1584895113,"creation_date":1334231888,"last_edit_date":1334232044,"question_id":10123104,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/10123104/unknown-command-crawl-error","title":"unknown command: crawl error"},{"tags":["python","web-crawler","scrapy","scrapy-spider","google-crawlers"],"owner":{"account_id":5535357,"reputation":3470,"user_id":4393898,"user_type":"registered","accept_rate":67,"profile_image":"https://i.stack.imgur.com/JvZg5.jpg?s=256&g=1","display_name":"yusuf","link":"https://stackoverflow.com/users/4393898/yusuf"},"is_answered":true,"view_count":13982,"accepted_answer_id":34383962,"answer_count":3,"score":35,"last_activity_date":1604997076,"creation_date":1450623970,"last_edit_date":1450625622,"question_id":34382356,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/34382356/passing-arguments-to-process-crawl-in-scrapy-python","title":"Passing arguments to process.crawl in Scrapy python"},{"tags":["python","python-3.x","scrapy","web-crawler"],"owner":{"account_id":4212859,"reputation":6683,"user_id":4440675,"user_type":"registered","accept_rate":70,"profile_image":"https://i.stack.imgur.com/q44sl.jpg?s=256&g=1","display_name":"Amit Tripathi","link":"https://stackoverflow.com/users/4440675/amit-tripathi"},"is_answered":true,"view_count":60901,"accepted_answer_id":30345296,"answer_count":3,"score":31,"last_activity_date":1622642973,"creation_date":1432104560,"last_edit_date":1622642973,"question_id":30342243,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/30342243/send-post-request-in-scrapy","title":"Send Post Request in Scrapy"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":1763444,"reputation":6665,"user_id":1762051,"user_type":"registered","accept_rate":28,"profile_image":"https://www.gravatar.com/avatar/64f024d7caf9fde67a8ca7c70c626db0?s=256&d=identicon&r=PG&f=1","display_name":"Alok","link":"https://stackoverflow.com/users/1762051/alok"},"is_answered":true,"view_count":21386,"accepted_answer_id":23131785,"answer_count":2,"score":29,"last_activity_date":1544619838,"creation_date":1397732232,"last_edit_date":1495541373,"question_id":23131283,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/23131283/how-to-force-scrapy-to-crawl-duplicate-url","title":"How to force scrapy to crawl duplicate url?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":4214747,"reputation":9253,"user_id":3451339,"user_type":"registered","accept_rate":87,"profile_image":"https://i.stack.imgur.com/HPuzK.png?s=256&g=1","display_name":"8-Bit Borges","link":"https://stackoverflow.com/users/3451339/8-bit-borges"},"is_answered":true,"view_count":36913,"closed_date":1568730895,"accepted_answer_id":43661172,"answer_count":6,"score":29,"last_activity_date":1648757779,"creation_date":1483651934,"last_edit_date":1497696614,"question_id":41495052,"link":"https://stackoverflow.com/questions/41495052/scrapy-reactor-not-restartable","closed_reason":"Duplicate","title":"Scrapy - Reactor not Restartable"},{"tags":["python","web-scraping","scrapy","web-crawler","pyspider"],"owner":{"account_id":403854,"reputation":449464,"user_id":771848,"user_type":"registered","accept_rate":100,"profile_image":"https://i.stack.imgur.com/2DTBv.jpg?s=256&g=1","display_name":"alecxe","link":"https://stackoverflow.com/users/771848/alecxe"},"is_answered":true,"view_count":9119,"accepted_answer_id":27246549,"answer_count":2,"score":26,"last_activity_date":1558659716,"creation_date":1417502033,"question_id":27243246,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/27243246/can-scrapy-be-replaced-by-pyspider","title":"Can Scrapy be replaced by pyspider?"},{"tags":["python","selenium","web-scraping","web-crawler","bioinformatics"],"owner":{"account_id":2104023,"reputation":7900,"user_id":1870832,"user_type":"registered","accept_rate":79,"profile_image":"https://i.stack.imgur.com/4zazd.png?s=256&g=1","display_name":"Max Power","link":"https://stackoverflow.com/users/1870832/max-power"},"is_answered":true,"view_count":18501,"accepted_answer_id":53966809,"answer_count":4,"score":25,"last_activity_date":1598409606,"creation_date":1544548711,"last_edit_date":1578087425,"question_id":53729201,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/53729201/save-complete-web-page-incl-css-images-using-python-selenium","title":"Save complete web page (incl css, images) using python/selenium"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":190962,"reputation":1151,"user_id":431222,"user_type":"registered","accept_rate":75,"profile_image":"https://i.stack.imgur.com/AHqJ8.jpg?s=256&g=1","display_name":"Adam F","link":"https://stackoverflow.com/users/431222/adam-f"},"is_answered":true,"view_count":21403,"accepted_answer_id":9570320,"answer_count":2,"score":24,"last_activity_date":1626967107,"creation_date":1330915427,"last_edit_date":1397502549,"question_id":9561020,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/9561020/how-do-i-use-the-python-scrapy-module-to-list-all-the-urls-from-my-website","title":"How do I use the Python Scrapy module to list all the URLs from my website?"},{"tags":["python","get","web-crawler"],"owner":{"account_id":144850,"reputation":524,"user_id":354208,"user_type":"registered","accept_rate":88,"profile_image":"https://www.gravatar.com/avatar/2a970d2ffe8e07b5879940b8e76f1f5e?s=256&d=identicon&r=PG","display_name":"Dan","link":"https://stackoverflow.com/users/354208/dan"},"is_answered":true,"view_count":111153,"accepted_answer_id":3533678,"answer_count":4,"score":24,"last_activity_date":1590588824,"creation_date":1282326882,"last_edit_date":1282327779,"question_id":3533528,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/3533528/python-web-crawlers-and-getting-html-source-code","title":"Python Web Crawlers and &quot;getting&quot; html source code"},{"tags":["python","cloud","web-crawler","virtual","server"],"owner":{"account_id":1402130,"reputation":957,"user_id":1330691,"user_type":"registered","accept_rate":0,"profile_image":"https://www.gravatar.com/avatar/a7ec3000fd8675cfdc5862d6f5eb58b7?s=256&d=identicon&r=PG","display_name":"user1330691","link":"https://stackoverflow.com/users/1330691/user1330691"},"is_answered":true,"view_count":28409,"answer_count":5,"score":24,"last_activity_date":1619556800,"creation_date":1415856223,"question_id":26901882,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/26901882/what-is-the-easiest-way-to-run-python-scripts-in-a-cloud-server","title":"What is the easiest way to run python scripts in a cloud server?"},{"tags":["python","regex","web-crawler","scrapy"],"owner":{"account_id":2991113,"reputation":799,"user_id":2538689,"user_type":"registered","accept_rate":47,"profile_image":"https://www.gravatar.com/avatar/295073d64d5fa7be6150fd849358bc7a?s=256&d=identicon&r=PG","display_name":"Vy.Iv","link":"https://stackoverflow.com/users/2538689/vy-iv"},"is_answered":true,"view_count":14224,"answer_count":3,"score":20,"last_activity_date":1489023405,"creation_date":1393543685,"last_edit_date":1438682108,"question_id":22082938,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/22082938/how-do-scrapy-rules-work-with-crawl-spider","title":"How do Scrapy rules work with crawl spider"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":146658,"reputation":25761,"user_id":357236,"user_type":"registered","accept_rate":67,"profile_image":"https://www.gravatar.com/avatar/6bdfd8b1fab6e88177b5064115418734?s=256&d=identicon&r=PG","display_name":"goh","link":"https://stackoverflow.com/users/357236/goh"},"is_answered":true,"view_count":14540,"accepted_answer_id":8532689,"answer_count":8,"score":19,"last_activity_date":1659446432,"creation_date":1324028261,"last_edit_date":1324033678,"question_id":8532252,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8532252/scrapy-logging-to-file-and-stdout-simultaneously-with-spider-names","title":"Scrapy - logging to file and stdout simultaneously, with spider names"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":11994425,"reputation":311,"user_id":8776466,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/fb1ca205692ece5caba8da1789b3ce94?s=256&d=identicon&r=PG&f=1","display_name":"gait","link":"https://stackoverflow.com/users/8776466/gait"},"is_answered":true,"view_count":31478,"answer_count":4,"score":19,"last_activity_date":1619518037,"creation_date":1507998000,"last_edit_date":1600638920,"question_id":46746701,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/46746701/scrapy-http-status-code-is-not-handled-or-not-allowed","title":"Scrapy: HTTP status code is not handled or not allowed?"},{"tags":["python","multithreading","scrapy","web-crawler"],"owner":{"account_id":2036328,"reputation":11838,"user_id":1818608,"user_type":"registered","accept_rate":44,"profile_image":"https://www.gravatar.com/avatar/2c7fd43d0ea66acaf6eadc8062693a50?s=256&d=identicon&r=PG","display_name":"Gill Bates","link":"https://stackoverflow.com/users/1818608/gill-bates"},"is_answered":true,"view_count":17264,"answer_count":4,"score":19,"last_activity_date":1661151937,"creation_date":1405435123,"last_edit_date":1655185827,"question_id":24761074,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/24761074/is-scrapy-single-threaded-or-multi-threaded","title":"Is Scrapy single-threaded or multi-threaded?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":2853319,"reputation":699,"user_id":2450030,"user_type":"registered","accept_rate":73,"profile_image":"https://www.gravatar.com/avatar/ac59c873690e510b04249f5a64c13936?s=256&d=identicon&r=PG","display_name":"Zhang Jiuzhou","link":"https://stackoverflow.com/users/2450030/zhang-jiuzhou"},"is_answered":true,"view_count":3320,"closed_date":1374816859,"accepted_answer_id":17872865,"answer_count":1,"score":19,"last_activity_date":1518712942,"creation_date":1374811813,"last_edit_date":1429939554,"question_id":17872753,"link":"https://stackoverflow.com/questions/17872753/what-is-the-difference-between-scrapys-spider-middleware-and-downloader-middlew","closed_reason":"Needs details or clarity","title":"What is the difference between Scrapy&#39;s spider middleware and downloader middleware?"},{"tags":["python","url","web-crawler"],"owner":{"account_id":2518971,"reputation":223,"user_id":2189704,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/7b90bb5555c6996848dbb430da1781b1?s=256&d=identicon&r=PG","display_name":"user2189704","link":"https://stackoverflow.com/users/2189704/user2189704"},"is_answered":true,"view_count":64787,"closed_date":1363769542,"answer_count":5,"score":18,"last_activity_date":1554086814,"creation_date":1363763739,"last_edit_date":1477309443,"question_id":15517483,"link":"https://stackoverflow.com/questions/15517483/how-to-extract-urls-from-an-html-page-in-python","closed_reason":"not a real question","title":"How to extract URLs from an HTML page in Python"},{"tags":["python","html","web-scraping","scrapy","web-crawler"],"owner":{"account_id":1733461,"reputation":465,"user_id":1586541,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/2964eb66ace94db95802f62919cad99b?s=256&d=identicon&r=PG","display_name":"inix","link":"https://stackoverflow.com/users/1586541/inix"},"is_answered":true,"view_count":28382,"accepted_answer_id":17722635,"answer_count":3,"score":18,"last_activity_date":1566518903,"creation_date":1374145727,"last_edit_date":1566518903,"question_id":17721782,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/17721782/is-it-possible-for-scrapy-to-get-plain-text-from-raw-html-data","title":"Is it possible for Scrapy to get plain text from raw HTML data?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":2341620,"reputation":1325,"user_id":2052781,"user_type":"registered","accept_rate":50,"profile_image":"https://www.gravatar.com/avatar/7d59dc23a4e74412f19263c1e5af35e0?s=256&d=identicon&r=PG","display_name":"gpanterov","link":"https://stackoverflow.com/users/2052781/gpanterov"},"is_answered":true,"view_count":7129,"accepted_answer_id":15839428,"answer_count":2,"score":18,"last_activity_date":1365181029,"creation_date":1365170837,"question_id":15836062,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/15836062/scrapy-crawlspider-doesnt-crawl-the-first-landing-page","title":"Scrapy CrawlSpider doesn&#39;t crawl the first landing page"},{"tags":["python","web","web-crawler","python-requests"],"owner":{"account_id":2085929,"reputation":2911,"user_id":1856928,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/69c595bf0e20d22324270c82c1ddbfb4?s=256&d=identicon&r=PG","display_name":"Acemad","link":"https://stackoverflow.com/users/1856928/acemad"},"is_answered":true,"view_count":19357,"accepted_answer_id":21009511,"answer_count":3,"score":18,"last_activity_date":1435793128,"creation_date":1389224571,"last_edit_date":1399405206,"question_id":21008953,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/21008953/python-requests-1-how-to-disable-keep-alive","title":"Python-Requests (&gt;= 1.*): How to disable keep-alive?"},{"tags":["python","selenium","web-scraping","beautifulsoup","web-crawler"],"owner":{"user_type":"does_not_exist","display_name":"user6866656"},"is_answered":true,"view_count":34793,"accepted_answer_id":53973459,"answer_count":4,"score":18,"last_activity_date":1633222735,"creation_date":1546118461,"question_id":53973423,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/53973423/getting-value-after-button-click-with-beautifulsoup-python","title":"Getting value after button click with BeautifulSoup Python"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":212122,"reputation":280776,"user_id":464744,"user_type":"registered","accept_rate":86,"profile_image":"https://www.gravatar.com/avatar/3dfd6067f4c69986a652444f44bb6d7c?s=256&d=identicon&r=PG","display_name":"Blender","link":"https://stackoverflow.com/users/464744/blender"},"is_answered":true,"view_count":11215,"accepted_answer_id":15580406,"answer_count":5,"score":17,"last_activity_date":1630605361,"creation_date":1363936662,"question_id":15564844,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/15564844/locally-run-all-of-the-spiders-in-scrapy","title":"Locally run all of the spiders in Scrapy"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":1383320,"reputation":329,"user_id":1315868,"user_type":"registered","accept_rate":57,"profile_image":"https://i.stack.imgur.com/akoye.png?s=256&g=1","display_name":"Sagi","link":"https://stackoverflow.com/users/1315868/sagi"},"is_answered":true,"view_count":8085,"answer_count":2,"score":17,"last_activity_date":1387741434,"creation_date":1381852926,"last_edit_date":1387741434,"question_id":19385837,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/19385837/python-scrapy-on-offline-local-data","title":"Python Scrapy on offline (local) data"},{"tags":["python","scrapy","web-crawler","pipeline"],"owner":{"account_id":410811,"reputation":1164,"user_id":782868,"user_type":"registered","accept_rate":77,"profile_image":"https://www.gravatar.com/avatar/59c78233162c86ba4c63879b033fa26c?s=256&d=identicon&r=PG","display_name":"John Lotacs","link":"https://stackoverflow.com/users/782868/john-lotacs"},"is_answered":true,"view_count":16192,"accepted_answer_id":7169241,"answer_count":3,"score":17,"last_activity_date":1412722234,"creation_date":1313765506,"last_edit_date":1400939900,"question_id":7123387,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/7123387/should-i-create-pipeline-to-save-files-with-scrapy","title":"Should I create pipeline to save files with scrapy?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":1343549,"reputation":171,"user_id":1284717,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/099b2514c921b5aabace1b497619f8c1?s=256&d=identicon&r=PG","display_name":"user1284717","link":"https://stackoverflow.com/users/1284717/user1284717"},"is_answered":true,"view_count":7283,"answer_count":5,"score":17,"last_activity_date":1424110627,"creation_date":1332375879,"last_edit_date":1495541265,"question_id":9814827,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/9814827/creating-a-generic-scrapy-spider","title":"Creating a generic scrapy spider"},{"tags":["python","url","scrapy","web-crawler"],"owner":{"account_id":1117614,"reputation":573,"user_id":1106607,"user_type":"registered","accept_rate":41,"profile_image":"https://www.gravatar.com/avatar/ca48e1494fc1ab557350b053c384ebf1?s=256&d=identicon&r=PG","display_name":"Sanket Gupta","link":"https://stackoverflow.com/users/1106607/sanket-gupta"},"is_answered":true,"view_count":13489,"accepted_answer_id":8588800,"answer_count":6,"score":16,"last_activity_date":1540300864,"creation_date":1324326709,"last_edit_date":1458302573,"question_id":8567171,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8567171/how-do-i-remove-a-query-from-a-url","title":"How do I remove a query from a url?"},{"tags":["python","web-crawler","web-scraping"],"owner":{"account_id":68708,"reputation":17082,"user_id":200317,"user_type":"registered","accept_rate":59,"profile_image":"https://www.gravatar.com/avatar/90ca39c2ec77b9727567834bdaacd72d?s=256&d=identicon&r=PG","display_name":"add-semi-colons","link":"https://stackoverflow.com/users/200317/add-semi-colons"},"is_answered":true,"view_count":48534,"accepted_answer_id":8377373,"answer_count":3,"score":16,"last_activity_date":1354567394,"creation_date":1323018888,"last_edit_date":1354567394,"question_id":8377055,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8377055/submit-data-via-web-form-and-extract-the-results","title":"Submit data via web form and extract the results"},{"tags":["python","scrapy","web-crawler","scrape","scrapy-spider"],"owner":{"account_id":5630530,"reputation":907,"user_id":4457613,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/66615b46a3c765986559d38b869ce572?s=256&d=identicon&r=PG&f=1","display_name":"sboss","link":"https://stackoverflow.com/users/4457613/sboss"},"is_answered":true,"view_count":26695,"accepted_answer_id":27978534,"answer_count":3,"score":16,"last_activity_date":1551099672,"creation_date":1421328123,"question_id":27964410,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/27964410/scrapy-only-follow-internal-urls-but-extract-all-links-found","title":"Scrapy, only follow internal URLS but extract all links found"},{"tags":["python","web-scraping","web-crawler","scrapy"],"owner":{"account_id":6258933,"reputation":403,"user_id":4866685,"user_type":"registered","accept_rate":75,"profile_image":"https://www.gravatar.com/avatar/6edbd2959097a84708efedeaf20d9e87?s=256&d=identicon&r=PG&f=1","display_name":"Arkan Kalu","link":"https://stackoverflow.com/users/4866685/arkan-kalu"},"is_answered":true,"view_count":20155,"accepted_answer_id":30152967,"answer_count":1,"score":16,"last_activity_date":1433689750,"creation_date":1431266199,"last_edit_date":1433689750,"question_id":30152261,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/30152261/make-scrapy-follow-links-and-collect-data","title":"Make Scrapy follow links and collect data"},{"tags":["python","web-scraping","scrapy","web-crawler","sitemap"],"owner":{"account_id":4916915,"reputation":543,"user_id":3960621,"user_type":"registered","accept_rate":60,"profile_image":"https://i.stack.imgur.com/jSkrl.jpg?s=256&g=1","display_name":"Michimcchicken","link":"https://stackoverflow.com/users/3960621/michimcchicken"},"is_answered":true,"view_count":21014,"answer_count":6,"score":16,"last_activity_date":1607505120,"creation_date":1463136236,"last_edit_date":1491957619,"question_id":37207959,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/37207959/how-to-scrape-all-contents-from-infinite-scroll-website-scrapy","title":"How to scrape all contents from infinite scroll website? scrapy"},{"tags":["python","matplotlib","charts","web-crawler"],"owner":{"account_id":13755434,"reputation":263,"user_id":9926510,"user_type":"registered","profile_image":"https://lh3.googleusercontent.com/-2W1tqf_2Mg4/AAAAAAAAAAI/AAAAAAAAAAA/AB6qoq3qPer4ww8UlzpUIIaDwMdzP9-zkQ/mo/photo.jpg?sz=256","display_name":"David Ko","link":"https://stackoverflow.com/users/9926510/david-ko"},"is_answered":true,"view_count":25895,"answer_count":2,"score":16,"last_activity_date":1644697680,"creation_date":1540070220,"last_edit_date":1634263173,"question_id":52910187,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/52910187/how-to-make-a-polygon-radar-spider-chart-in-python","title":"How to make a polygon radar (spider) chart in python"},{"tags":["python","solr","web-scraping","scrapy","web-crawler"],"owner":{"account_id":2025012,"reputation":183,"user_id":1810283,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1","display_name":"Vidhu","link":"https://stackoverflow.com/users/1810283/vidhu"},"is_answered":true,"view_count":11396,"closed_date":1532832427,"accepted_answer_id":17200157,"answer_count":1,"score":16,"last_activity_date":1480708134,"creation_date":1371669272,"last_edit_date":1418015253,"question_id":17199457,"link":"https://stackoverflow.com/questions/17199457/scrapy-vs-nutch","closed_reason":"Needs more focus","title":"Scrapy Vs Nutch"},{"tags":["python","scrapy","web-crawler","twisted","scrapy-spider"],"owner":{"account_id":1469310,"reputation":1139,"user_id":1381263,"user_type":"registered","accept_rate":63,"profile_image":"https://i.stack.imgur.com/TE7hG.jpg?s=256&g=1","display_name":"Ahsan aslam","link":"https://stackoverflow.com/users/1381263/ahsan-aslam"},"is_answered":true,"view_count":8649,"answer_count":5,"score":15,"last_activity_date":1626970109,"creation_date":1477392419,"last_edit_date":1477394922,"question_id":40237952,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/40237952/get-scrapy-crawler-output-results-in-script-file-function","title":"Get Scrapy crawler output/results in script file function"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":214074,"reputation":573,"user_id":467829,"user_type":"registered","accept_rate":9,"profile_image":"https://www.gravatar.com/avatar/7855dc465fdcc84d1cdeed02aaf9e736?s=256&d=identicon&r=PG","display_name":"Avinash","link":"https://stackoverflow.com/users/467829/avinash"},"is_answered":true,"view_count":9799,"answer_count":5,"score":15,"last_activity_date":1578452029,"creation_date":1286361512,"last_edit_date":1460555854,"question_id":3871613,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/3871613/scrapy-how-to-identify-already-scraped-urls","title":"Scrapy - how to identify already scraped urls"},{"tags":["python","web-scraping","scrapy","web-crawler","user-agent"],"owner":{"account_id":1763444,"reputation":6665,"user_id":1762051,"user_type":"registered","accept_rate":28,"profile_image":"https://www.gravatar.com/avatar/64f024d7caf9fde67a8ca7c70c626db0?s=256&d=identicon&r=PG&f=1","display_name":"Alok","link":"https://stackoverflow.com/users/1762051/alok"},"is_answered":true,"view_count":20847,"answer_count":4,"score":14,"last_activity_date":1512027936,"creation_date":1397818786,"last_edit_date":1461557159,"question_id":23152739,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/23152739/how-to-make-scrapy-show-user-agent-per-download-request-in-log","title":"How to make Scrapy show user agent per download request in log?"},{"tags":["python","web-crawler","mechanize","robots.txt"],"owner":{"account_id":428304,"reputation":747,"user_id":810540,"user_type":"registered","accept_rate":60,"profile_image":"https://www.gravatar.com/avatar/ef2488905b7ee3aa369ca5b346d2a33e?s=256&d=identicon&r=PG","display_name":"Craig Locke","link":"https://stackoverflow.com/users/810540/craig-locke"},"is_answered":true,"view_count":12685,"accepted_answer_id":8386555,"answer_count":2,"score":14,"last_activity_date":1323094233,"creation_date":1323093902,"question_id":8386481,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8386481/web-crawler-ignore-robots-txt-file","title":"Web Crawler - Ignore Robots.txt file?"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":168089,"reputation":6109,"user_id":393304,"user_type":"registered","accept_rate":68,"profile_image":"https://i.stack.imgur.com/fgrGM.jpg?s=256&g=1","display_name":"del","link":"https://stackoverflow.com/users/393304/del"},"is_answered":true,"view_count":5701,"answer_count":2,"score":14,"last_activity_date":1347347380,"creation_date":1318588485,"question_id":7766414,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/7766414/replay-a-scrapy-spider-on-stored-data","title":"Replay a Scrapy spider on stored data"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":360280,"reputation":283,"user_id":702200,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/4ea32ee87a4ed74efcef48b8443a2a07?s=256&d=identicon&r=PG","display_name":"aniketd","link":"https://stackoverflow.com/users/702200/aniketd"},"is_answered":true,"view_count":8569,"accepted_answer_id":9699317,"answer_count":1,"score":14,"last_activity_date":1380251664,"creation_date":1331717101,"last_edit_date":1495541837,"question_id":9699049,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/9699049/how-do-i-stop-all-spiders-and-the-engine-immediately-after-a-condition-in-a-pipe","title":"How do I stop all spiders and the engine immediately after a condition in a pipeline is met?"},{"tags":["python","web-crawler"],"owner":{"account_id":359787,"reputation":613,"user_id":701409,"user_type":"registered","accept_rate":79,"profile_image":"https://www.gravatar.com/avatar/f21305009ffc9ea31ca20ee04d1faecd?s=256&d=identicon&r=PG","display_name":"McEnroe","link":"https://stackoverflow.com/users/701409/mcenroe"},"is_answered":true,"view_count":68292,"accepted_answer_id":8335661,"answer_count":4,"score":12,"last_activity_date":1439408844,"creation_date":1322704286,"question_id":8335630,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/8335630/how-to-crawl-a-website-extract-data-into-database-with-python","title":"How to crawl a website/extract data into database with python?"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":7254,"reputation":15582,"user_id":12534,"user_type":"registered","accept_rate":94,"profile_image":"https://www.gravatar.com/avatar/c248df6104953c22e814d3f4f65b3839?s=256&d=identicon&r=PG","display_name":"Christian Dav&#233;n","link":"https://stackoverflow.com/users/12534/christian-dav%c3%a9n"},"is_answered":true,"view_count":7417,"accepted_answer_id":2397334,"answer_count":4,"score":12,"last_activity_date":1482199503,"creation_date":1267971218,"last_edit_date":1267971527,"question_id":2396529,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/2396529/using-one-scrapy-spider-for-several-websites","title":"Using one Scrapy spider for several websites"},{"tags":["python","scrapy","web-crawler","robots.txt","scrapy-shell"],"owner":{"account_id":2166851,"reputation":392,"user_id":1919798,"user_type":"registered","accept_rate":100,"profile_image":"https://www.gravatar.com/avatar/9971f444a26b48ce6727821326dffa20?s=256&d=identicon&r=PG","display_name":"DARDAR SAAD","link":"https://stackoverflow.com/users/1919798/dardar-saad"},"is_answered":true,"view_count":10855,"accepted_answer_id":40823612,"answer_count":2,"score":11,"last_activity_date":1480202892,"creation_date":1480196952,"last_edit_date":1480200151,"question_id":40823516,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/40823516/how-to-disable-robots-txt-when-you-launch-scrapy-shell","title":"How to disable robots.txt when you launch scrapy shell?"},{"tags":["python","web-crawler","scrapy","scrapy-spider"],"owner":{"account_id":7310436,"reputation":127,"user_id":5569854,"user_type":"registered","profile_image":"https://graph.facebook.com/173891566291760/picture?type=large","display_name":"Gh057","link":"https://stackoverflow.com/users/5569854/gh057"},"is_answered":true,"view_count":15542,"answer_count":5,"score":11,"last_activity_date":1635680381,"creation_date":1447720377,"last_edit_date":1447720524,"question_id":33747174,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/33747174/how-to-specify-parameters-on-a-request-using-scrapy","title":"How to specify parameters on a Request using scrapy"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":1437582,"reputation":675,"user_id":1358630,"user_type":"registered","accept_rate":69,"profile_image":"https://www.gravatar.com/avatar/0b1a7af0933051fe8c98e04665dcecd9?s=256&d=identicon&r=PG","display_name":"hoof_hearted","link":"https://stackoverflow.com/users/1358630/hoof-hearted"},"is_answered":true,"view_count":9686,"accepted_answer_id":12145164,"answer_count":3,"score":11,"last_activity_date":1346083239,"creation_date":1346081868,"question_id":12145067,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/12145067/scrapy-select-specific-link-based-on-text","title":"Scrapy - Select specific link based on text"},{"tags":["python","selenium","selenium-webdriver","web-scraping","web-crawler"],"owner":{"account_id":1751412,"reputation":665,"user_id":3970193,"user_type":"registered","accept_rate":67,"profile_image":"https://www.gravatar.com/avatar/c8603ff901556ada8180282750eda599?s=256&d=identicon&r=PG","display_name":"Gaara","link":"https://stackoverflow.com/users/3970193/gaara"},"is_answered":true,"view_count":15739,"accepted_answer_id":30455695,"answer_count":3,"score":11,"last_activity_date":1432645772,"creation_date":1432625950,"last_edit_date":1432635523,"question_id":30452395,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/30452395/selenium-pdf-automatic-download-not-working","title":"Selenium pdf automatic download not working"},{"tags":["python","scrapy","web-crawler","scrapy-spider"],"owner":{"account_id":5798827,"reputation":3289,"user_id":4573703,"user_type":"registered","accept_rate":90,"profile_image":"https://www.gravatar.com/avatar/1692103db4bb79442bb0dd5f3bd1b104?s=256&d=identicon&r=PG&f=1","display_name":"ocean800","link":"https://stackoverflow.com/users/4573703/ocean800"},"is_answered":true,"view_count":12869,"accepted_answer_id":44528146,"answer_count":1,"score":11,"last_activity_date":1497375522,"creation_date":1497375005,"question_id":44527996,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/44527996/scrapy-understanding-crawlspider-and-linkextractor","title":"Scrapy - Understanding CrawlSpider and LinkExtractor"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":106182,"reputation":923,"user_id":282953,"user_type":"registered","accept_rate":44,"profile_image":"https://www.gravatar.com/avatar/0bd736f69a9b6349b9196e3c5cbb9d7f?s=256&d=identicon&r=PG","display_name":"superb","link":"https://stackoverflow.com/users/282953/superb"},"is_answered":true,"view_count":5778,"accepted_answer_id":2350109,"answer_count":2,"score":11,"last_activity_date":1471491027,"creation_date":1267330033,"question_id":2350049,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/2350049/how-to-build-a-web-crawler-based-on-scrapy-to-run-forever","title":"How to build a web crawler based on Scrapy to run forever?"},{"tags":["python","selenium","python-requests","web-crawler","cloudflare"],"owner":{"account_id":18645740,"reputation":111,"user_id":13592667,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/6c1eaa381575c1bddedf4645f54d38b9?s=256&d=identicon&r=PG&f=1","display_name":"ku8zi","link":"https://stackoverflow.com/users/13592667/ku8zi"},"is_answered":true,"view_count":3771,"answer_count":3,"score":11,"last_activity_date":1620767090,"creation_date":1590750721,"question_id":62084602,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/62084602/how-does-cloudflare-differentiate-selenium-and-requests-traffic","title":"How does Cloudflare differentiate Selenium and Requests traffic?"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":6290913,"reputation":871,"user_id":4888655,"user_type":"registered","accept_rate":32,"profile_image":"https://www.gravatar.com/avatar/a45327f0079fd201c15b9bc4b9d5d43b?s=256&d=identicon&r=PG&f=1","display_name":"printemp","link":"https://stackoverflow.com/users/4888655/printemp"},"is_answered":true,"view_count":5736,"accepted_answer_id":31233576,"answer_count":2,"score":10,"last_activity_date":1436120672,"creation_date":1436114670,"last_edit_date":1436115039,"question_id":31232681,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/31232681/scrapy-crawler-caught-exception-reading-instance-data","title":"scrapy crawler caught exception reading instance data"},{"tags":["python","scrapy","web-crawler","scrapyd"],"owner":{"account_id":8418743,"reputation":125,"user_id":6318171,"user_type":"registered","profile_image":"https://lh4.googleusercontent.com/-7CqYms27UHA/AAAAAAAAAAI/AAAAAAAAAgE/vKY4u1HoWxk/photo.jpg?sz=256","display_name":"dropax","link":"https://stackoverflow.com/users/6318171/dropax"},"is_answered":true,"view_count":3757,"accepted_answer_id":45753444,"answer_count":1,"score":10,"last_activity_date":1503049192,"creation_date":1503040769,"last_edit_date":1503041556,"question_id":45750739,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/45750739/scrapyd-client-command-not-found","title":"scrapyd-client command not found"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":6258933,"reputation":403,"user_id":4866685,"user_type":"registered","accept_rate":75,"profile_image":"https://www.gravatar.com/avatar/6edbd2959097a84708efedeaf20d9e87?s=256&d=identicon&r=PG&f=1","display_name":"Arkan Kalu","link":"https://stackoverflow.com/users/4866685/arkan-kalu"},"is_answered":true,"view_count":10825,"accepted_answer_id":30410408,"answer_count":1,"score":10,"last_activity_date":1519219977,"creation_date":1432322312,"question_id":30404364,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/30404364/scrapy-delay-request","title":"Scrapy delay request"},{"tags":["python","proxy","screen-scraping","web-crawler","squid"],"owner":{"account_id":48631,"reputation":4164,"user_id":144563,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/348a20c3a576b2cb26674f1bc9eaf012?s=256&d=identicon&r=PG","display_name":"Jacob","link":"https://stackoverflow.com/users/144563/jacob"},"is_answered":true,"view_count":16831,"protected_date":1624645595,"accepted_answer_id":1934198,"answer_count":3,"score":10,"last_activity_date":1624544256,"creation_date":1261255581,"question_id":1934088,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/1934088/rotating-proxies-for-web-scraping","title":"Rotating Proxies for web scraping"},{"tags":["python","web-scraping","scrapy","web-crawler","scrapy-spider"],"owner":{"account_id":6799010,"reputation":337,"user_id":7008941,"user_type":"registered","accept_rate":83,"profile_image":"https://www.gravatar.com/avatar/85d955a7b00d0d0e3bcff292d2ab8a85?s=256&d=identicon&r=PG&f=1","display_name":"student","link":"https://stackoverflow.com/users/7008941/student"},"is_answered":true,"view_count":7532,"accepted_answer_id":40609976,"answer_count":2,"score":10,"last_activity_date":1575881028,"creation_date":1478583824,"last_edit_date":1482442602,"question_id":40479789,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/40479789/how-to-scrape-all-the-content-of-each-link-with-scrapy","title":"How to scrape all the content of each link with scrapy?"},{"tags":["python","parsing","web-crawler","yandex"],"owner":{"account_id":13594643,"reputation":255,"user_id":9807062,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/003216fd0dc9e2efba50b25da4f35c16?s=256&d=identicon&r=PG&f=1","display_name":"Platon Makovsky","link":"https://stackoverflow.com/users/9807062/platon-makovsky"},"is_answered":true,"view_count":6866,"accepted_answer_id":62136342,"answer_count":2,"score":10,"last_activity_date":1648902853,"creation_date":1590264973,"last_edit_date":1591027729,"question_id":61978049,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/61978049/reverse-search-an-image-in-yandex-images-using-python","title":"Reverse search an image in Yandex Images using Python"},{"tags":["python","python-3.x","scrapy","web-crawler"],"owner":{"account_id":5668383,"reputation":370,"user_id":4483879,"user_type":"registered","accept_rate":50,"profile_image":"https://www.gravatar.com/avatar/8949fbfe1e61a0fd2d7d29e66ce95b4b?s=256&d=identicon&r=PG&f=1","display_name":"Brandon Skerritt","link":"https://stackoverflow.com/users/4483879/brandon-skerritt"},"is_answered":true,"view_count":16782,"answer_count":2,"score":10,"last_activity_date":1546823485,"creation_date":1519383682,"question_id":48946320,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/48946320/scrapy-get-all-links-from-any-website","title":"Scrapy get all links from any website"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":305455,"reputation":103,"user_id":615623,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/b7910d1b0b8eaf40963c4148f025bf9a?s=256&d=identicon&r=PG","display_name":"Adam Smith","link":"https://stackoverflow.com/users/615623/adam-smith"},"is_answered":true,"view_count":16576,"accepted_answer_id":5019817,"answer_count":2,"score":10,"last_activity_date":1469024932,"creation_date":1297649883,"last_edit_date":1469024932,"question_id":4988297,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/4988297/trying-to-get-scrapy-into-a-project-to-run-crawl-command","title":"Trying to get Scrapy into a project to run Crawl command"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":74936,"reputation":12767,"user_id":215094,"user_type":"registered","accept_rate":93,"profile_image":"https://www.gravatar.com/avatar/e1ac4523231d2f61e24813a574a2f08f?s=256&d=identicon&r=PG","display_name":"Zeynel","link":"https://stackoverflow.com/users/215094/zeynel"},"is_answered":true,"view_count":4247,"accepted_answer_id":2074821,"answer_count":1,"score":10,"last_activity_date":1322503573,"creation_date":1259368463,"question_id":1811132,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/1811132/scrapy-sgmllinkextractor-is-ignoring-allowed-links","title":"Scrapy SgmlLinkExtractor is ignoring allowed links"},{"tags":["python","selenium","web-crawler","scrapy"],"owner":{"account_id":68708,"reputation":17082,"user_id":200317,"user_type":"registered","accept_rate":59,"profile_image":"https://www.gravatar.com/avatar/90ca39c2ec77b9727567834bdaacd72d?s=256&d=identicon&r=PG","display_name":"add-semi-colons","link":"https://stackoverflow.com/users/200317/add-semi-colons"},"is_answered":true,"view_count":26637,"answer_count":5,"score":9,"last_activity_date":1656445314,"creation_date":1395968336,"last_edit_date":1397505776,"question_id":22702277,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/22702277/crawl-site-that-has-infinite-scrolling-using-python","title":"crawl site that has infinite scrolling using python"},{"tags":["python","html","concurrency","web-crawler"],"owner":{"account_id":72306,"reputation":24127,"user_id":208827,"user_type":"registered","accept_rate":69,"profile_image":"https://www.gravatar.com/avatar/0b455a88803f79d121493a95ff119937?s=256&d=identicon&r=PG","display_name":"RadiantHex","link":"https://stackoverflow.com/users/208827/radianthex"},"is_answered":true,"view_count":6657,"answer_count":4,"score":9,"last_activity_date":1327574917,"creation_date":1267492497,"last_edit_date":1275520948,"question_id":2360291,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/2360291/concurrent-downloads-python","title":"Concurrent downloads - Python"},{"tags":["python","web-crawler"],"owner":{"account_id":10692241,"reputation":423,"user_id":7877399,"user_type":"registered","accept_rate":50,"profile_image":"https://www.gravatar.com/avatar/68d5d177e8967b4df35fb45c42cf82ee?s=256&d=identicon&r=PG&f=1","display_name":"man","link":"https://stackoverflow.com/users/7877399/man"},"is_answered":true,"view_count":47460,"accepted_answer_id":43447546,"answer_count":5,"score":9,"last_activity_date":1648441300,"creation_date":1492414441,"last_edit_date":1492414888,"question_id":43447221,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/43447221/removing-all-spaces-in-text-file-with-python-3-x","title":"Removing all spaces in text file with Python 3.x"},{"tags":["python","web-scraping","scrapy","web-crawler"],"owner":{"account_id":5052139,"reputation":401,"user_id":4056384,"user_type":"registered","accept_rate":88,"profile_image":"https://lh5.googleusercontent.com/-1stxw1QVLM4/AAAAAAAAAAI/AAAAAAAAABA/ER_WFItPoTQ/photo.jpg?sz=256","display_name":"E liquid Vape","link":"https://stackoverflow.com/users/4056384/e-liquid-vape"},"is_answered":true,"view_count":9828,"accepted_answer_id":27810497,"answer_count":1,"score":9,"last_activity_date":1628073372,"creation_date":1420573200,"last_edit_date":1420577750,"question_id":27805952,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/27805952/scrapy-set-depth-limit-per-allowed-domains","title":"Scrapy set depth limit per allowed_domains"},{"tags":["python","mysql","scrapy","web-crawler"],"owner":{"account_id":1385323,"reputation":153,"user_id":1317498,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/b1cbd980bcd0df9a2393d04d3a6fae31?s=256&d=identicon&r=PG","display_name":"maryo","link":"https://stackoverflow.com/users/1317498/maryo"},"is_answered":true,"view_count":4713,"accepted_answer_id":20137164,"answer_count":2,"score":9,"last_activity_date":1403040920,"creation_date":1385030719,"question_id":20118753,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/20118753/python-scrapy-populate-start-urls-from-mysql","title":"Python Scrapy - populate start_urls from mysql"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":74936,"reputation":12767,"user_id":215094,"user_type":"registered","accept_rate":93,"profile_image":"https://www.gravatar.com/avatar/e1ac4523231d2f61e24813a574a2f08f?s=256&d=identicon&r=PG","display_name":"Zeynel","link":"https://stackoverflow.com/users/215094/zeynel"},"is_answered":true,"view_count":8574,"accepted_answer_id":1818537,"answer_count":4,"score":9,"last_activity_date":1377788890,"creation_date":1259341930,"question_id":1809817,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/1809817/scrapy-sgmllinkextractor-question","title":"Scrapy SgmlLinkExtractor question"},{"tags":["python","beautifulsoup","web-crawler","html-parsing"],"owner":{"account_id":8372953,"reputation":311,"user_id":6287439,"user_type":"registered","accept_rate":67,"profile_image":"https://i.stack.imgur.com/eHEU3.jpg?s=256&g=1","display_name":"Valeria Lobos Ossand&#243;n","link":"https://stackoverflow.com/users/6287439/valeria-lobos-ossand%c3%b3n"},"is_answered":true,"view_count":17060,"answer_count":1,"score":9,"last_activity_date":1482185403,"creation_date":1466701279,"last_edit_date":1482185403,"question_id":37997702,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/37997702/how-to-convert-a-string-into-a-beautifulsoup-object","title":"How to convert a String into a BeautifulSoup object?"},{"tags":["python","web-crawler","scrapy"],"owner":{"account_id":154154,"reputation":829,"user_id":369890,"user_type":"registered","accept_rate":62,"profile_image":"https://i.stack.imgur.com/whVQl.jpg?s=256&g=1","display_name":"romeroqj","link":"https://stackoverflow.com/users/369890/romeroqj"},"is_answered":true,"view_count":6606,"accepted_answer_id":6593158,"answer_count":2,"score":9,"last_activity_date":1309938661,"creation_date":1309922876,"question_id":6591255,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/6591255/following-links-scrapy-web-crawler-framework","title":"Following links, Scrapy web crawler framework"},{"tags":["python","json","scrapy","web-crawler"],"owner":{"account_id":2365484,"reputation":91,"user_id":2071236,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/ec2d0c0cd41add145c1bcde043162ca1?s=256&d=identicon&r=PG","display_name":"user2071236","link":"https://stackoverflow.com/users/2071236/user2071236"},"is_answered":true,"view_count":2523,"answer_count":1,"score":9,"last_activity_date":1360833083,"creation_date":1360830860,"last_edit_date":1360832554,"question_id":14870694,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/14870694/how-to-collect-data-from-multiple-pages-into-single-data-structure-with-scrapy","title":"How to collect data from multiple pages into single data structure with scrapy"},{"tags":["python","scrapy","web-crawler","scrapy-splash","splash-js-render"],"owner":{"account_id":204788,"reputation":813,"user_id":2533426,"user_type":"registered","accept_rate":47,"profile_image":"https://www.gravatar.com/avatar/416043ea00c0535011134cc6b750e01b?s=256&d=identicon&r=PG","display_name":"eN_Joy","link":"https://stackoverflow.com/users/2533426/en-joy"},"is_answered":true,"view_count":3630,"answer_count":3,"score":9,"last_activity_date":1574238612,"creation_date":1503679517,"last_edit_date":1574238612,"question_id":45886068,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/45886068/scrapy-crawlspider-splash-how-to-follow-links-through-linkextractor","title":"Scrapy CrawlSpider + Splash: how to follow links through linkextractor?"},{"tags":["python","web-crawler","google-scholar"],"owner":{"account_id":8088875,"reputation":191,"user_id":6095487,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/aff7232e6e17cea3c327dff4f5c4bbe6?s=256&d=identicon&r=PG&f=1","display_name":"Peter","link":"https://stackoverflow.com/users/6095487/peter"},"is_answered":true,"view_count":4547,"answer_count":2,"score":9,"last_activity_date":1645194363,"creation_date":1459197912,"question_id":36270867,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/36270867/crawling-google-scholar","title":"Crawling Google Scholar"},{"tags":["python","url","scrapy","url-encoding","web-crawler"],"owner":{"account_id":4782671,"reputation":93,"user_id":3863990,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1","display_name":"flyingtriangle","link":"https://stackoverflow.com/users/3863990/flyingtriangle"},"is_answered":true,"view_count":2601,"accepted_answer_id":42494437,"answer_count":1,"score":9,"last_activity_date":1488224647,"creation_date":1406022389,"question_id":24884011,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/24884011/how-to-prevent-scrapy-from-url-encoding-request-urls","title":"How to prevent Scrapy from URL encoding request URLs"},{"tags":["python","django","scrapy","web-crawler"],"owner":{"account_id":11663663,"reputation":1061,"user_id":8541064,"user_type":"registered","accept_rate":57,"profile_image":"https://www.gravatar.com/avatar/6c4e915fcfb1f99f7c6b78c1b7bc3603?s=256&d=identicon&r=PG&f=1","display_name":"bonblow","link":"https://stackoverflow.com/users/8541064/bonblow"},"is_answered":true,"view_count":20284,"accepted_answer_id":46067426,"answer_count":3,"score":8,"last_activity_date":1559112885,"creation_date":1504674911,"last_edit_date":1504676311,"question_id":46067258,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/46067258/scrapy-save-response-body-as-html-file","title":"Scrapy: Save response.body as html file?"},{"tags":["python","selenium","automation","web-crawler","bots"],"owner":{"account_id":8096916,"reputation":171,"user_id":6101193,"user_type":"registered","accept_rate":25,"profile_image":"https://i.stack.imgur.com/WXGi2.jpg?s=256&g=1","display_name":"Daniyal Tariq","link":"https://stackoverflow.com/users/6101193/daniyal-tariq"},"is_answered":true,"view_count":14382,"accepted_answer_id":45654226,"answer_count":2,"score":8,"last_activity_date":1609410287,"creation_date":1502551505,"question_id":45651879,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/45651879/using-selenium-how-to-keep-logged-in-after-closing-driver-in-python","title":"Using selenium: How to keep logged in after closing Driver in Python"},{"tags":["python","multithreading","web-crawler","web-mining"],"owner":{"account_id":204046,"reputation":1451,"user_id":452027,"user_type":"registered","accept_rate":88,"profile_image":"https://www.gravatar.com/avatar/b2b7c939dcb9d7ddcbd18765b067ac7b?s=256&d=identicon&r=PG","display_name":"pbp","link":"https://stackoverflow.com/users/452027/pbp"},"is_answered":true,"view_count":7371,"accepted_answer_id":7653340,"answer_count":5,"score":8,"last_activity_date":1395169070,"creation_date":1317757867,"last_edit_date":1350221698,"question_id":7653276,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/7653276/fast-internet-crawler","title":"Fast internet crawler"},{"tags":["python","selenium","beautifulsoup","web-crawler","urllib2"],"owner":{"account_id":6973537,"reputation":1091,"user_id":5348990,"user_type":"registered","accept_rate":36,"profile_image":"https://www.gravatar.com/avatar/bf9b29188c0f8f2318a5e14dc1ca7319?s=256&d=identicon&r=PG&f=1","display_name":"jackycflau","link":"https://stackoverflow.com/users/5348990/jackycflau"},"is_answered":true,"view_count":1086,"accepted_answer_id":43164454,"answer_count":1,"score":8,"last_activity_date":1554802482,"creation_date":1491104612,"last_edit_date":1554802482,"question_id":43164411,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/43164411/why-do-we-still-need-parser-like-beautifulsoup-if-we-can-use-selenium","title":"Why do we still need parser like BeautifulSoup if we can use Selenium?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":1416564,"reputation":24208,"user_id":1342109,"user_type":"registered","accept_rate":56,"profile_image":"https://www.gravatar.com/avatar/9c47b3a7fb3f67fb8efe8b7e8636dd59?s=256&d=identicon&r=PG&f=1","display_name":"Shiva Krishna Bavandla","link":"https://stackoverflow.com/users/1342109/shiva-krishna-bavandla"},"is_answered":true,"view_count":8179,"accepted_answer_id":10944103,"answer_count":4,"score":8,"last_activity_date":1508655631,"creation_date":1339135123,"question_id":10943745,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/10943745/running-multiple-spiders-in-scrapy","title":"Running Multiple spiders in scrapy"},{"tags":["python","python-2.7","web-scraping","web-crawler","scrapy"],"owner":{"account_id":4854983,"reputation":1073,"user_id":3916237,"user_type":"registered","accept_rate":56,"profile_image":"https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1","display_name":"dkx22","link":"https://stackoverflow.com/users/3916237/dkx22"},"is_answered":true,"view_count":9226,"accepted_answer_id":31071124,"answer_count":2,"score":8,"last_activity_date":1495704977,"creation_date":1435313832,"last_edit_date":1435314553,"question_id":31070660,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/31070660/scrapy-get-all-children-ignore-br","title":"Scrapy get all children / ignore &lt;br&gt;?"},{"tags":["python","scrapy","web-crawler"],"owner":{"account_id":895696,"reputation":89,"user_id":933044,"user_type":"registered","accept_rate":25,"profile_image":"https://www.gravatar.com/avatar/2f832696dc710b576e09ba96284f5915?s=256&d=identicon&r=PG","display_name":"Jonno","link":"https://stackoverflow.com/users/933044/jonno"},"is_answered":true,"view_count":5288,"answer_count":2,"score":8,"last_activity_date":1602531370,"creation_date":1372418232,"last_edit_date":1602531370,"question_id":17363458,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/17363458/running-code-when-scrapy-spider-has-finished-crawling","title":"Running code when Scrapy spider has finished crawling"},{"tags":["python","web-crawler","pipeline","scrapy","scraper"],"owner":{"account_id":153141,"reputation":9631,"user_id":368186,"user_type":"registered","accept_rate":88,"profile_image":"https://www.gravatar.com/avatar/fa7a595e20675cd352ea78597ed1acf0?s=256&d=identicon&r=PG","display_name":"Jim Jeffries","link":"https://stackoverflow.com/users/368186/jim-jeffries"},"is_answered":true,"view_count":7614,"accepted_answer_id":4100942,"answer_count":2,"score":8,"last_activity_date":1288901879,"creation_date":1288812070,"last_edit_date":1288899612,"question_id":4090795,"content_license":"CC BY-SA 2.5","link":"https://stackoverflow.com/questions/4090795/cant-get-scrapy-pipeline-to-work","title":"Can&#39;t get Scrapy pipeline to work"},{"tags":["python","selenium","web-crawler"],"owner":{"account_id":6697473,"reputation":687,"user_id":5165095,"user_type":"registered","accept_rate":77,"profile_image":"https://www.gravatar.com/avatar/8c9a0f900e44d54ac973a40c563fc66d?s=256&d=identicon&r=PG&f=1","display_name":"Serious Ruffy","link":"https://stackoverflow.com/users/5165095/serious-ruffy"},"is_answered":true,"view_count":26089,"accepted_answer_id":32077953,"answer_count":1,"score":8,"last_activity_date":1607811720,"creation_date":1439823836,"last_edit_date":1490868678,"question_id":32053746,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/32053746/selenium-find-all-elements-by-xpath","title":"Selenium find all elements by xpath"},{"tags":["python","web-scraping","beautifulsoup","web-crawler"],"owner":{"account_id":1481189,"reputation":830,"user_id":1390536,"user_type":"registered","accept_rate":59,"profile_image":"https://www.gravatar.com/avatar/ad365d54a89f3d99c916cda407aacaf5?s=256&d=identicon&r=PG","display_name":"Harrison","link":"https://stackoverflow.com/users/1390536/harrison"},"is_answered":true,"view_count":3417,"answer_count":2,"score":8,"last_activity_date":1638200057,"creation_date":1401311639,"last_edit_date":1401402835,"question_id":23921986,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/23921986/web-scraping-without-knowledge-of-page-structure","title":"Web scraping without knowledge of page structure"},{"tags":["python","beautifulsoup","web-crawler"],"owner":{"account_id":1828769,"reputation":5235,"user_id":1660802,"user_type":"registered","accept_rate":71,"profile_image":"https://www.gravatar.com/avatar/2cb346768fc8a144fb6f98d7b38a93cc?s=256&d=identicon&r=PG","display_name":"Lucas Ou-Yang","link":"https://stackoverflow.com/users/1660802/lucas-ou-yang"},"is_answered":true,"view_count":4113,"accepted_answer_id":14165771,"answer_count":2,"score":8,"last_activity_date":1612777967,"creation_date":1357330892,"last_edit_date":1612777967,"question_id":14164350,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/14164350/identifying-large-bodies-of-text-via-beautifulsoup-or-other-python-based-extract","title":"Identifying large bodies of text via BeautifulSoup or other python based extractors"},{"tags":["python","web-scraping","python-requests","web-crawler"],"owner":{"account_id":2699611,"reputation":193,"user_id":2330624,"user_type":"registered","accept_rate":89,"profile_image":"https://www.gravatar.com/avatar/5bba0fd359ff5f9ad35ab961be93b64e?s=256&d=identicon&r=PG&f=1","display_name":"user2330624","link":"https://stackoverflow.com/users/2330624/user2330624"},"is_answered":true,"view_count":2512,"answer_count":1,"score":8,"last_activity_date":1609441560,"creation_date":1546455909,"last_edit_date":1609441560,"question_id":54011831,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/54011831/captcha-using-requests-even-after-changing-headers-and-ip-how-am-i-being-tracke","title":"Captcha using requests even after changing headers and IP. How am I being tracked?"},{"tags":["python","scrapy","rules","web-crawler"],"owner":{"account_id":1414680,"reputation":822,"user_id":1340563,"user_type":"registered","accept_rate":44,"profile_image":"https://www.gravatar.com/avatar/4fe9f1612a11a2fdd449ec722e1cb0b1?s=256&d=identicon&r=PG","display_name":"OfLettersAndNumbers","link":"https://stackoverflow.com/users/1340563/oflettersandnumbers"},"is_answered":true,"view_count":3943,"answer_count":1,"score":8,"last_activity_date":1490461964,"creation_date":1408780207,"last_edit_date":1408811761,"question_id":25459719,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/25459719/understanding-scrapys-crawlspider-rules","title":"Understanding Scrapy&#39;s CrawlSpider rules"},{"tags":["python","http","scrapy","web-crawler"],"owner":{"account_id":159805,"reputation":231,"user_id":379436,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/3bd654cf78d6afea4c9768437c4c3e6c?s=256&d=identicon&r=PG","display_name":"somewire","link":"https://stackoverflow.com/users/379436/somewire"},"is_answered":true,"view_count":4173,"answer_count":1,"score":8,"last_activity_date":1354023470,"creation_date":1353552308,"question_id":13505194,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/13505194/scrapy-crawling-speed-is-slow-60-pages-min","title":"Scrapy Crawling Speed is Slow (60 pages / min)"},{"tags":["python","database","url","storage","web-crawler"],"owner":{"account_id":120979,"reputation":103,"user_id":313743,"user_type":"registered","profile_image":"https://www.gravatar.com/avatar/e38737083ac59c796ff7020ffabb639b?s=256&d=identicon&r=PG","display_name":"user313743","link":"https://stackoverflow.com/users/313743/user313743"},"is_answered":true,"view_count":1231,"accepted_answer_id":2615836,"answer_count":6,"score":7,"last_activity_date":1437805930,"creation_date":1270952392,"last_edit_date":1437805837,"question_id":2615830,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/2615830/storing-urls-while-spidering","title":"Storing URLs while Spidering"},{"tags":["python","web-scraping","scrapy","web-crawler","scrapy-spider"],"owner":{"account_id":5733013,"reputation":2175,"user_id":4527978,"user_type":"registered","accept_rate":94,"profile_image":"https://i.stack.imgur.com/Od9E3.png?s=256&g=1","display_name":"parik","link":"https://stackoverflow.com/users/4527978/parik"},"is_answered":true,"view_count":20154,"accepted_answer_id":39366885,"answer_count":3,"score":7,"last_activity_date":1630535064,"creation_date":1473237685,"last_edit_date":1532092929,"question_id":39365131,"content_license":"CC BY-SA 4.0","link":"https://stackoverflow.com/questions/39365131/running-multiple-spiders-in-scrapy-for-1-website-in-parallel","title":"Running Multiple spiders in scrapy for 1 website in parallel?"},{"tags":["python","regex","web-scraping","scrapy","web-crawler"],"owner":{"account_id":1171598,"reputation":953,"user_id":1148668,"user_type":"registered","accept_rate":67,"profile_image":"https://i.stack.imgur.com/IOEti.jpg?s=256&g=1","display_name":"Muhammet Arslan","link":"https://stackoverflow.com/users/1148668/muhammet-arslan"},"is_answered":true,"view_count":3804,"accepted_answer_id":23662143,"answer_count":2,"score":7,"last_activity_date":1513140523,"creation_date":1400091174,"last_edit_date":1513140523,"question_id":23662069,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/23662069/scrapy-parse-javascript","title":"Scrapy parse javascript"},{"tags":["python","html","selenium","beautifulsoup","web-crawler"],"owner":{"account_id":8829504,"reputation":309,"user_id":7315250,"user_type":"registered","accept_rate":50,"profile_image":"https://www.gravatar.com/avatar/9e512cba94cdd3b77693802495b8cfee?s=256&d=identicon&r=PG&f=1","display_name":"Revaapriyan","link":"https://stackoverflow.com/users/7315250/revaapriyan"},"is_answered":true,"view_count":25139,"accepted_answer_id":46933925,"answer_count":3,"score":7,"last_activity_date":1607139561,"creation_date":1508937901,"last_edit_date":1508953230,"question_id":46933679,"content_license":"CC BY-SA 3.0","link":"https://stackoverflow.com/questions/46933679/scraping-text-in-h3-and-div-tags-using-beautifulsoup-python","title":"Scraping text in h3 and div tags using beautifulSoup, Python"}],"has_more":true,"quota_max":300,"quota_remaining":293}